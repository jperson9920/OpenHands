# docker-compose.yml
services:
  openhands:
    image: ghcr.io/all-hands-ai/openhands:latest
    container_name: openhands-main
    restart: unless-stopped
    environment:
      - LLM_MODEL=openai/qwen2.5-coder-32b-instruct
      - LLM_BASE_URL=https://integrate.api.nvidia.com/v1
      - LLM_API_KEY=${NVIDIA_NIM_API_KEY}
      - LLM_CUSTOM_LLM_PROVIDER=openai
      - SANDBOX_TIMEOUT=300
      - LOG_ALL_EVENTS=true
      - SANDBOX_VOLUMES=${SANDBOX_VOLUMES}
      - AGENT_DEFAULT_MODEL=openai/qwen2.5-coder-32b-instruct
    volumes:
      - ./workspace:/workspace
      - ./prompts:/app/prompts:ro
      - ./logs:/app/logs
      # Mount SSH keys for GitHub access
      - ${USERPROFILE}/.ssh:/root/.ssh:ro
    ports:
      - "3000:3000"  # OpenHands default UI
      - "3001:3001"  # WebSocket for real-time updates
    networks:
      - openhands-network

  custom-dashboard:
    build:
      context: ./custom-dashboard
      dockerfile: Dockerfile
    container_name: openhands-dashboard
    restart: unless-stopped
    ports:
      - "8080:80"  # Custom dashboard web UI
    depends_on:
      - openhands
    networks:
      - openhands-network
    volumes:
      - ./custom-dashboard:/app
      - ./logs:/app/logs:ro
    environment:
      - OPENHANDS_API_URL=http://openhands:3000

networks:
  openhands-network:
    driver: bridge